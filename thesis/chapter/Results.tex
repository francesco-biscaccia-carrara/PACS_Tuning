%intro%
\section{Experimental Setup}
The experiments are designed to compare the PACS framework with the standalone IBM ILOG CPLEX Optimization Studio (version 22.1).  
The PACS framework is implemented in C++ for performance reasons, interfacing with the solver through the C API. The source code is available under a non-commercial MIP license at \textbf{[repository link]}.  
All experiments were conducted on a cluster within the UniPD DEI Blade infrastructure, running Rocky Linux 8.10. Each node is equipped with an Intel(R) Xeon(R) E5-2623 v3 processor (4 cores, 3.00 GHz) and 16 GB of RAM. Although the infrastructure is cluster-based, the computational power of a single node is comparable to that of a general-purpose laptop, or even lower.  
For fairness in comparison, PACS executions use 4 logical threads, implemented as C++ standard threads, each running a CPLEX instance restricted to a single core. The baseline counterpart is a standalone CPLEX execution restricted to 4 cores.

\subsection{Dataset}
As anticipated in the previous sections, the benchmark for this comparison must consist of hard MIP instances. To this end, the set of hard instances from MIPLIB2017$^\text{\cite{MIPLIB}}$ has been used as the test bed.\footnote{The instance \textit{tpl-tub-ss16} was excluded, as its execution was terminated due to insufficient computational resources.}  
While CPLEX directly processes each MIP instance, the PACS framework additionally requires a random seed in order to reproduce the same randomized choices across different runs. For this purpose, PACS was evaluated on each instance using the seeds $\{38472910, 56473829, 27384910, 91827364, 8374659\}$. This setup increases statistical reliability and can be considered representative of the algorithmâ€™s standard behavior.  
Consequently, for each instance, five independent PACS runs and one CPLEX run were executed.

\subsection{Metrics}
Both PACS and plain CPLEX terminate as soon as an incumbent solution (i.e., a feasible solution) is identified, subject to a global time limit of five minutes.
Since the PACS framework was executed five times for each instance, the reported solution quality and computation time are given as the mean across all runs.
Moreover, if the majority of PACS executions for a given instance---at least three out of five seeds---fail to produce a solution, the instance is recorded as unsolved.
Instead of directly comparing the objective values of the solutions returned by the two approaches, the MIP gap metric$^\text{\cite{MIPGAP}}$ has been adopted. The MIP gap is defined as follows: given a solution $\hat{x}$ for a MIP with an optimal solution $x$, the primal gap $\gamma(\hat{x}) \in [0,1]$ is
\begin{equation}
\gamma(\hat{x}) =
\begin{cases}
0 & \text{if } |c^T x| = |c^T \hat{x}| = 0, \\
1 & \text{if } c^T x \cdot c^T \hat{x}< 0, \\
\frac{|c^T x-c^T \hat{x}|}{\max\{|c^T \hat{x}|, |c^T x|\}} & \text{otherwise}.
\end{cases}
\end{equation}
This metric captures the relative gap between an incumbent and the best-known solution, normalized to the interval $[0,1]$.  
Since the algorithms operate under a strict time limit, the metric must be extended accordingly. Given a time limit $t_{\max}$, the primal function $p:[0,t_{\max}] \to [0,1]$ is defined as:
\begin{equation}
p(\hat{x}) =
\begin{cases}
1 & \text{if no solution is found up to time $t$}, \\
\gamma(\hat{x}(t)) & \text{if $\hat{x}(t)$ is the incumbent at time $t$}.
\end{cases}
\end{equation}
For each test, two types of plots are produced to summarize and compare performance:
\begin{enumerate}
    \item \textbf{Success Rate vs. Computation Time:}  
    The $x$-axis represents elapsed time, and the $y$-axis reports the cumulative number of instances for which an incumbent was found. The closer a curve is to the top-left corner, the more efficient the algorithm.  
    \item \textbf{Success Rate vs. MIP Gap:}  
    The $x$-axis represents the MIP gap, and the $y$-axis reports the cumulative number of instances solved with a gap less than or equal to the given value. Consistently, curves closer to the top-left corner indicate better performance 
\end{enumerate}

\subsection{Tolerance Parameters}
Because both algorithms involve floating-point computations and comparisons, PACS employs a set of tolerance parameters. In these experiments, the parameters were selected to be reasonable relative to the defaults used by CPLEX:
\begin{itemize}
    \item \textbf{Zero-tolerance parameter} $\epsilon$: values smaller than $\epsilon$ are treated as zero. In all tests, $\epsilon$ was set to $10^{-5}$.
    \item \textbf{Absolute maximum constraint violation}: the maximum permissible violation of any constraint under a candidate solution $\hat{x}$. In these tests, it was set equal to $\epsilon$, i.e., $10^{-5}$.
    \item \textbf{Absolute maximum integrality violation}: the maximum deviation allowed for variables constrained to take integer values. This tolerance was likewise set to $\epsilon = 10^{-5}$.
    \item \textbf{Relative objective error}: the maximum admissible relative error between the recomputed objective value $c^T \hat{x}$ and the value stored internally by PACS. This threshold was again set to $\epsilon = 10^{-5}$.  
\end{itemize}  
In the latter three cases, if the corresponding tolerance is exceeded, the algorithm terminates with an error and the run is recorded as unsolved.  

\section{Results}
%
%\subsection for the single experiments
%
%